import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib

class VulnerabilityModelTrainer:
    def __init__(self):
        # Initialize a standard scaler to normalize the input features
        self.scaler = StandardScaler()

        # Initialize a Random Forest classifier with 100 trees and a fixed random seed
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)

    def load_data(self, data: pd.DataFrame):
        """
        Load feature data and separate the labels.
        :param data: A pandas DataFrame that includes both features and a 'label' column.
        """
        self.X = data.drop("label", axis=1)  # Features
        self.y = data["label"]               # Labels

    def preprocess(self):
        """
        Normalize the features using standard scaling (zero mean, unit variance).
        """
        self.X_scaled = self.scaler.fit_transform(self.X)

    def train(self, test_size=0.25):
        """
        Split the data into training and testing sets, train the model,
        and return the accuracy on the test set.
        :param test_size: The proportion of the dataset to include in the test split.
        :return: Accuracy score of the model on the test set.
        """
        X_train, X_test, y_train, y_test = train_test_split(
            self.X_scaled, self.y, test_size=test_size, random_state=42
        )
        self.model.fit(X_train, y_train)
        return self.model.score(X_test, y_test)

    def save(self, model_path="rf_model.pkl", scaler_path="scaler.pkl"):
        """
        Save the trained model and scaler to disk for later use.
        :param model_path: Path to save the model file.
        :param scaler_path: Path to save the scaler file.
        """
        joblib.dump(self.model, model_path)
        joblib.dump(self.scaler, scaler_path)
