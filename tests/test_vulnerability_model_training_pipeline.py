import os
import unittest
import pandas as pd
import joblib
from prod.VulnerabilityModelTrainingPipeline import VulnerabilityModelTrainingPipeline

class TestVulnerabilityModelTrainingPipeline(unittest.TestCase):
    def setUp(self):
        """
        Prepare the test dataset and configure file paths before each test.
        """
        # Create a synthetic dataset: one vulnerability per row
        self.test_data_path = "test_training_data.csv"
        data = pd.DataFrame([
            {
                "generally_dangerous_calls": 1,
                "unprotected_critical_calls": 0,
                "tainted_input_in_dangerous_calls": 0,
                "tainted_param_source_calls": 0,
                "dangerous_dynamic_sql": 0,
                "tainted_flows": 0,
                "missing_error_handling": 0,
                "deep_control_nesting": 0,
                "uninitialized_variable_usage": 0,
                "tainted_file_access": 0,
                "unsafe_deserialization": 0,
                "buffer_overflow_risk": 0,
                "severity": "Low",
                "confidence": 0.8
            },
            {
                "generally_dangerous_calls": 0,
                "unprotected_critical_calls": 1,
                "tainted_input_in_dangerous_calls": 0,
                "tainted_param_source_calls": 0,
                "dangerous_dynamic_sql": 0,
                "tainted_flows": 0,
                "missing_error_handling": 0,
                "deep_control_nesting": 0,
                "uninitialized_variable_usage": 0,
                "tainted_file_access": 0,
                "unsafe_deserialization": 0,
                "buffer_overflow_risk": 0,
                "severity": "High",
                "confidence": 0.6
            },
            {
                "generally_dangerous_calls": 0,
                "unprotected_critical_calls": 0,
                "tainted_input_in_dangerous_calls": 0,
                "tainted_param_source_calls": 0,
                "dangerous_dynamic_sql": 1,
                "tainted_flows": 0,
                "missing_error_handling": 0,
                "deep_control_nesting": 0,
                "uninitialized_variable_usage": 0,
                "tainted_file_access": 0,
                "unsafe_deserialization": 0,
                "buffer_overflow_risk": 0,
                "severity": "High",
                "confidence": 0.9
            }
        ])
        data.to_csv(self.test_data_path, index=False)

        # Define temporary model paths
        self.severity_path = "../model/severity_model.pkl"
        self.confidence_path = "../model/confidence_model.pkl"
        self.scaler_path = "../model/scaler.pkl"

        # Instantiate the pipeline
        self.pipeline = VulnerabilityModelTrainingPipeline(
            data_path=self.test_data_path,
            model_severity_path=self.severity_path,
            model_confidence_path=self.confidence_path,
            scaler_path=self.scaler_path
        )

    def test_pipeline_training_and_saving(self):
        """
        Test the end-to-end training and saving of the models and scaler.
        """
        # Use production training data
        self.pipeline.data_path = "../training_data/training_data.csv"

        # Run pipeline steps
        self.pipeline.load_data()
        self.pipeline.preprocess()
        acc_sev, r2_conf = self.pipeline.train()

        # Validate model metrics
        self.assertGreaterEqual(acc_sev, 0.0)
        self.assertLessEqual(acc_sev, 1.0)
        self.assertGreaterEqual(r2_conf, 0.0)
        self.assertLessEqual(r2_conf, 1.0)

        # Save trained components
        self.pipeline.save_models()

        # Verify output files exist
        self.assertTrue(os.path.exists(self.severity_path))
        self.assertTrue(os.path.exists(self.confidence_path))
        self.assertTrue(os.path.exists(self.scaler_path))

        # Load models and check they're valid
        model_sev = joblib.load(self.severity_path)
        model_conf = joblib.load(self.confidence_path)
        scaler = joblib.load(self.scaler_path)

        self.assertIsNotNone(model_sev)
        self.assertIsNotNone(model_conf)
        self.assertIsNotNone(scaler)

    def test_empty_dataset(self):
        """
        Verify that an empty dataset raises an error.
        """
        empty_path = "empty.csv"
        pd.DataFrame().to_csv(empty_path, index=False)

        pipeline = VulnerabilityModelTrainingPipeline(data_path=empty_path)
        with self.assertRaises(Exception):
            pipeline.load_data()

        os.remove(empty_path)

    def test_missing_columns(self):
        """
        Verify that missing required columns triggers an error.
        """
        incomplete_path = "incomplete.csv"
        df = pd.DataFrame([{"generally_dangerous_calls": 1, "confidence": 0.5}])  # Missing 'severity'
        df.to_csv(incomplete_path, index=False)

        pipeline = VulnerabilityModelTrainingPipeline(data_path=incomplete_path)
        with self.assertRaises(KeyError):
            pipeline.load_data()

        os.remove(incomplete_path)

    def test_extreme_values(self):
        """Test if the pipeline can handle extreme but valid numerical values."""
        df = pd.DataFrame([{
            "generally_dangerous_calls": 999,
            "unprotected_critical_calls": 0,
            "tainted_input_in_dangerous_calls": 0,
            "tainted_param_source_calls": 0,
            "dangerous_dynamic_sql": 0,
            "tainted_flows": 0,
            "missing_error_handling": 0,
            "deep_control_nesting": 0,
            "uninitialized_variable_usage": 0,
            "tainted_file_access": 0,
            "unsafe_deserialization": 0,
            "buffer_overflow_risk": 0,
            "severity": "High",
            "confidence": 1.0
        }])
        df.to_csv(self.test_data_path, index=False)

        pipeline = VulnerabilityModelTrainingPipeline(
            data_path=self.test_data_path,
            model_severity_path=self.severity_path,
            model_confidence_path=self.confidence_path,
            scaler_path=self.scaler_path
        )

        pipeline.run_pipeline()

        self.assertTrue(os.path.exists(self.severity_path))
        self.assertTrue(os.path.exists(self.confidence_path))
        self.assertTrue(os.path.exists(self.scaler_path))

    def test_invalid_values(self):
        """Test if the pipeline raises errors on invalid (non-numeric) input."""
        df = pd.DataFrame([{
            "generally_dangerous_calls": "invalid",  # Invalid input
            "unprotected_critical_calls": 0,
            "tainted_input_in_dangerous_calls": 0,
            "tainted_param_source_calls": 0,
            "dangerous_dynamic_sql": 0,
            "tainted_flows": 0,
            "missing_error_handling": 0,
            "deep_control_nesting": 0,
            "uninitialized_variable_usage": 0,
            "tainted_file_access": 0,
            "unsafe_deserialization": 0,
            "buffer_overflow_risk": 0,
            "severity": "Low",
            "confidence": 0.5
        }])
        df.to_csv(self.test_data_path, index=False)

        pipeline = VulnerabilityModelTrainingPipeline(
            data_path=self.test_data_path,
            model_severity_path=self.severity_path,
            model_confidence_path=self.confidence_path,
            scaler_path=self.scaler_path
        )

        with self.assertRaises(Exception):
            pipeline.run_pipeline()

if __name__ == "__main__":
    unittest.main()
